{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "from creme import compose\n",
    "from creme import feature_extraction\n",
    "from creme import naive_bayes\n",
    "import creme"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "docs = [ ('Chinse Beijing Chinese', 'yes'), ('Chinese Chincese Shangai', 'yes'),('Chinese Macao', 'yes'), ('Tokyo Japan Chinese', 'no')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Chinse Beijing Chinese', 'yes'),\n",
       " ('Chinese Chincese Shangai', 'yes'),\n",
       " ('Chinese Macao', 'yes'),\n",
       " ('Tokyo Japan Chinese', 'no')]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = compose.Pipeline(\n",
    "    ('tokenize', feature_extraction.BagOfWords(lowercase=False)),\n",
    "    ('nb', naive_bayes.MultinomialNB(alpha=1))\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'this': 0.49236596391733095, 'is': 0.49236596391733095, 'the': 0.49236596391733095, 'first': 0.24618298195866548, 'document': 0.36927447293799814, 'second': 0.12309149097933274, 'docmunent': 0.12309149097933274, 'and': 0.12309149097933274, 'thirt': 0.12309149097933274, 'one': 0.12309149097933274}\n"
     ]
    }
   ],
   "source": [
    "#This is just and example\n",
    "\n",
    "corpus = [\n",
    "    'This is the first document.'\n",
    "    'This document is the second docmunent.'\n",
    "    'And this is the thirt one.'\n",
    "    'Is this the first document?'\n",
    "]\n",
    "\n",
    "bow = creme.feature_extraction.TFIDF()\n",
    "for sentence in corpus:\n",
    "    print(bow.transform_one(sentence))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 0 ns\n",
      "Wall time: 0 ns\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "for sentence, label in docs:\n",
    "    model = model.fit_one(sentence, label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_unseen = \"India USA Tokyo\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'no'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict_one(new_unseen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline (\n",
       "  BagOfWords (\n",
       "    on=None\n",
       "    strip_accents=True\n",
       "    lowercase=False\n",
       "    preprocessor=None\n",
       "    tokenizer=<built-in method findall of re.Pattern object at 0x000002D940CE9000>\n",
       "    ngram_range=(1, 1)\n",
       "  ),\n",
       "  MultinomialNB (\n",
       "    alpha=1\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Training for the new data \n",
    "model.fit_one('Tokyo India USA', 'no')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b> Taining for the new data and new category:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline (\n",
       "  BagOfWords (\n",
       "    on=None\n",
       "    strip_accents=True\n",
       "    lowercase=False\n",
       "    preprocessor=None\n",
       "    tokenizer=<built-in method findall of re.Pattern object at 0x000002D940CE9000>\n",
       "    ngram_range=(1, 1)\n",
       "  ),\n",
       "  MultinomialNB (\n",
       "    alpha=1\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit_one('Taiwan Honkong Tibet', 'may be')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'may be'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict_one('Taiwan Canada')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pandas in c:\\programdata\\anaconda3\\envs\\database\\lib\\site-packages (2.2.1)\n",
      "Requirement already satisfied: numpy<2,>=1.26.0 in c:\\programdata\\anaconda3\\envs\\database\\lib\\site-packages (from pandas) (1.26.4)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\programdata\\anaconda3\\envs\\database\\lib\\site-packages (from pandas) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\programdata\\anaconda3\\envs\\database\\lib\\site-packages (from pandas) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\programdata\\anaconda3\\envs\\database\\lib\\site-packages (from pandas) (2024.1)\n",
      "Requirement already satisfied: six>=1.5 in c:\\programdata\\anaconda3\\envs\\database\\lib\\site-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#NLP\n",
    "import pandas as pd\n",
    "\n",
    "messege = pd.read_csv('smsspamcollection/SMSSpamCollection', sep='\\t', names=[\"label\", \"message\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5572, 2)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "messege.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "messege_train, messege_test = train_test_split(messege)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>message</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1708</th>\n",
       "      <td>ham</td>\n",
       "      <td>Was doing my test earlier. I appreciate you. W...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2410</th>\n",
       "      <td>ham</td>\n",
       "      <td>Aww that's the first time u said u missed me w...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1326</th>\n",
       "      <td>ham</td>\n",
       "      <td>Yeah jay's sort of a fucking retard</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3710</th>\n",
       "      <td>ham</td>\n",
       "      <td>Ok.ok ok..then..whats ur todays plan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5421</th>\n",
       "      <td>ham</td>\n",
       "      <td>Hi elaine, is today's meeting confirmed?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1314</th>\n",
       "      <td>ham</td>\n",
       "      <td>How abt making some of the pics bigger?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3042</th>\n",
       "      <td>ham</td>\n",
       "      <td>Aight what time you want me to come up?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2546</th>\n",
       "      <td>ham</td>\n",
       "      <td>So are you guys asking that i get that slipper...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5018</th>\n",
       "      <td>spam</td>\n",
       "      <td>Dear 0776xxxxxxx U've been invited to XCHAT. T...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2070</th>\n",
       "      <td>spam</td>\n",
       "      <td>Eerie Nokia tones 4u, rply TONE TITLE to 8007 ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4179 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     label                                            message\n",
       "1708   ham  Was doing my test earlier. I appreciate you. W...\n",
       "2410   ham  Aww that's the first time u said u missed me w...\n",
       "1326   ham                Yeah jay's sort of a fucking retard\n",
       "3710   ham               Ok.ok ok..then..whats ur todays plan\n",
       "5421   ham           Hi elaine, is today's meeting confirmed?\n",
       "...    ...                                                ...\n",
       "1314   ham            How abt making some of the pics bigger?\n",
       "3042   ham            Aight what time you want me to come up?\n",
       "2546   ham  So are you guys asking that i get that slipper...\n",
       "5018  spam  Dear 0776xxxxxxx U've been invited to XCHAT. T...\n",
       "2070  spam  Eerie Nokia tones 4u, rply TONE TITLE to 8007 ...\n",
       "\n",
       "[4179 rows x 2 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "messege_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Converting Dataframe to tuples\n",
    "\n",
    "messege_train = messege_train.to_records(index= False)\n",
    "messege_test = messege_test.to_records(index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "rec.array([('ham', 'Was doing my test earlier. I appreciate you. Will call you tomorrow.'),\n",
       "           ('ham', \"Aww that's the first time u said u missed me without asking if I missed u first. You DO love me! :)\"),\n",
       "           ('ham', \"Yeah jay's sort of a fucking retard\"), ...,\n",
       "           ('ham', 'So are you guys asking that i get that slippers again or its gone with last year'),\n",
       "           ('spam', \"Dear 0776xxxxxxx U've been invited to XCHAT. This is our final attempt to contact u! Txt CHAT to 86688 150p/MsgrcvdHG/Suite342/2Lands/Row/W1J6HL LDN 18yrs\"),\n",
       "           ('spam', 'Eerie Nokia tones 4u, rply TONE TITLE to 8007 eg TONE DRACULA to 8007 Titles: GHOST, ADDAMSFA, MUNSTERS, EXORCIST, TWILIGHT www.getzed.co.uk POBox36504W45WQ 150p ')],\n",
       "          dtype=[('label', 'O'), ('message', 'O')])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "messege_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating the pipeline\n",
    "# 1st function is creating the TFIDF\n",
    "# 2nd function is the naive bayes predictor\n",
    "import math\n",
    "from creme import compose\n",
    "from creme import feature_extraction\n",
    "from creme import naive_bayes\n",
    "import creme\n",
    "model = compose.Pipeline(\n",
    "    ('tokenize', feature_extraction.TFIDF(lowercase=False)),\n",
    "    ('nb', naive_bayes.MultinomialNB(alpha=1))\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from creme import metrics\n",
    "metric=metrics.Accuracy()\n",
    "# Training the model row by row\n",
    "for label,sentence in messege_train:\n",
    "    model = model.fit_one(sentence, label)\n",
    "    y_pred = model.predict_one(sentence)\n",
    "    metric = metric.update(label, y_pred)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Accuracy: 95.79%"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### Training Data Accuracy\n",
    "metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "### test Data Accuracy\n",
    "test_metric=metrics.Accuracy()\n",
    "for label,sentence in messege_test:\n",
    "    y_pred = model.predict_one(sentence)\n",
    "    test_metric = metric.update(label, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Accuracy: 96.09%"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### test Metric\n",
    "test_metric"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Creme with Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Accuracy: 89.20%"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from creme import compose\n",
    "from creme import datasets\n",
    "from creme import linear_model\n",
    "from creme import metrics\n",
    "from creme import preprocessing\n",
    "\n",
    "X_y = datasets.Phishing()\n",
    "\n",
    "model = compose.Pipeline(\n",
    "   preprocessing.StandardScaler(),\n",
    " linear_model.LogisticRegression()\n",
    ")\n",
    "metric = metrics.Accuracy()\n",
    "\n",
    "\n",
    "for x, y in X_y:\n",
    "    y_pred = model.predict_one(x)      # make a prediction\n",
    "    metric = metric.update(y, y_pred)  # update the metric\n",
    "    model = model.fit_one(x, y)        # make the model learn\n",
    "\n",
    "metric"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "database",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
